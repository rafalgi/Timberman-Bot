{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a4dc86d-43f3-4072-96b7-acaa0e3720c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting image number 0\n",
      "Collecting image number 1\n",
      "Collecting image number 2\n",
      "Collecting image number 3\n",
      "Collecting image number 4\n",
      "Collecting image number 5\n",
      "Collecting image number 6\n",
      "Collecting image number 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(imgname, corrected_colors)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Wait for 2 seconds\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import time\n",
    "import os\n",
    "import pyautogui\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mss\n",
    "\n",
    "dimensionsLeft = {\n",
    "        'top': 50,\n",
    "        'left': 650,\n",
    "        'width': 400,\n",
    "        'height': 800\n",
    "}\n",
    "\n",
    "dimensionsRight = {\n",
    "        'top': 50,\n",
    "        'left': 1000,\n",
    "        'width': 400,\n",
    "        'height': 800\n",
    "}\n",
    "   \n",
    "IMAGES_PATH = os.path.join('data', 'images')\n",
    "labels = ['left_log', 'right_log', 'timberman']\n",
    "number_imgs = 20\n",
    "with mss.mss() as sct:\n",
    "\n",
    "    for img_num in range(number_imgs):\n",
    "        print(f'Collecting image number {img_num}')\n",
    "        \n",
    "        # Capture screenshot\n",
    "        screen = sct.grab(dimensionsRight)\n",
    "        \n",
    "        # Convert screenshot to a numpy array\n",
    "        screen_array = np.array(screen)\n",
    "        \n",
    "        # Convert colors from RGB to BGR (OpenCV uses BGR by default)\n",
    "        corrected_colors = cv2.cvtColor(screen_array, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Generate a unique filename\n",
    "        imgname = os.path.join(IMAGES_PATH, f'{uuid.uuid1()}.jpg')\n",
    "        \n",
    "        # Save the image\n",
    "        cv2.imwrite(imgname, corrected_colors)\n",
    "        \n",
    "        # Wait for 2 seconds\n",
    "        time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "568f81b0-4422-44ed-9c68-71f24a3c3a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.82 available đź�� Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.81 đźš€ Python-3.11.9 torch-2.2.2+cpu CPU (Intel Core(TM) i7-9700K 3.60GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=config.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train21, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\dzago\\runs\\detect\\train21\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir C:\\Users\\dzago\\runs\\detect\\train21', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: R:\\Deep Learning\\Timberman - Bot\\Data\\labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "Plotting labels to C:\\Users\\dzago\\runs\\detect\\train21\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âś…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\dzago\\runs\\detect\\train21\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         40         40      0.532      0.119      0.038     0.0203\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         40         40      0.507        0.5     0.0738     0.0461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         40         40      0.226      0.172      0.217      0.176\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         40         40      0.355      0.289      0.349       0.27\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         40         40      0.231      0.474      0.335       0.26\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         40         40      0.268      0.593      0.313      0.256\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         40         40      0.382      0.804      0.404      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         40         40      0.427      0.903      0.452      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         40         40        0.5      0.996      0.629      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         40         40      0.502          1      0.661      0.576\n",
      "\n",
      "10 epochs completed in 0.062 hours.\n",
      "Optimizer stripped from C:\\Users\\dzago\\runs\\detect\\train21\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from C:\\Users\\dzago\\runs\\detect\\train21\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating C:\\Users\\dzago\\runs\\detect\\train21\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.81 đźš€ Python-3.11.9 torch-2.2.2+cpu CPU (Intel Core(TM) i7-9700K 3.60GHz)\n",
      "Model summary (fused): 168 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                   all         40         40      0.501      0.985       0.66      0.576\n",
      "                  left         21         21      0.534          1      0.847      0.742\n",
      "                 right         19         19      0.467       0.97      0.473      0.409\n",
      "Speed: 0.8ms preprocess, 63.8ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\dzago\\runs\\detect\\train21\u001b[0m\n",
      "đź’ˇ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dzago\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning R:\\Deep Learning\\Timberman - Bot\\Data\\labels...:   0%|          | 0/40 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning R:\\Deep Learning\\Timberman - Bot\\Data\\labels... 40 images, 0 backgrounds, 0 corrupt: 100%|##########| 40/40 [00:00<00:00, 877.30it/s]\n",
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.14 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning R:\\Deep Learning\\Timberman - Bot\\Data\\labels.cache... 40 images, 0 backgrounds, 0 corrupt: 100%|##########| 40/40 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning R:\\Deep Learning\\Timberman - Bot\\Data\\labels.cache... 40 images, 0 backgrounds, 0 corrupt: 100%|##########| 40/40 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       1/10         0G      2.243       8.87      2.128         16        640:   0%|          | 0/3 [00:07<?, ?it/s]\n",
      "       1/10         0G      2.243       8.87      2.128         16        640:  33%|###3      | 1/3 [00:07<00:15,  7.92s/it]\n",
      "       1/10         0G       2.31      9.547      2.193         16        640:  33%|###3      | 1/3 [00:15<00:15,  7.92s/it]\n",
      "       1/10         0G       2.31      9.547      2.193         16        640:  67%|######6   | 2/3 [00:15<00:07,  7.78s/it]\n",
      "       1/10         0G      2.214       8.61      2.095          8        640:  67%|######6   | 2/3 [00:18<00:07,  7.78s/it]\n",
      "       1/10         0G      2.214       8.61      2.095          8        640: 100%|##########| 3/3 [00:18<00:00,  5.75s/it]\n",
      "       1/10         0G      2.214       8.61      2.095          8        640: 100%|##########| 3/3 [00:18<00:00,  6.31s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|#####     | 1/2 [00:03<00:03,  3.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:04<00:00,  1.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:04<00:00,  2.04s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       2/10         0G      2.155      6.327      2.149         16        640:   0%|          | 0/3 [00:07<?, ?it/s]\n",
      "       2/10         0G      2.155      6.327      2.149         16        640:  33%|###3      | 1/3 [00:07<00:14,  7.40s/it]\n",
      "       2/10         0G      2.018      5.932      2.066         16        640:  33%|###3      | 1/3 [00:14<00:14,  7.40s/it]\n",
      "       2/10         0G      2.018      5.932      2.066         16        640:  67%|######6   | 2/3 [00:14<00:07,  7.39s/it]\n",
      "       2/10         0G      1.704      5.187      1.792          8        640:  67%|######6   | 2/3 [00:17<00:07,  7.39s/it]\n",
      "       2/10         0G      1.704      5.187      1.792          8        640: 100%|##########| 3/3 [00:17<00:00,  5.43s/it]\n",
      "       2/10         0G      1.704      5.187      1.792          8        640: 100%|##########| 3/3 [00:17<00:00,  5.96s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|#####     | 1/2 [00:02<00:02,  2.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.62s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       3/10         0G     0.9067      3.029       1.18         16        640:   0%|          | 0/3 [00:07<?, ?it/s]\n",
      "       3/10         0G     0.9067      3.029       1.18         16        640:  33%|###3      | 1/3 [00:07<00:14,  7.24s/it]\n",
      "       3/10         0G       0.86      2.916      1.123         16        640:  33%|###3      | 1/3 [00:14<00:14,  7.24s/it]\n",
      "       3/10         0G       0.86      2.916      1.123         16        640:  67%|######6   | 2/3 [00:14<00:07,  7.46s/it]\n",
      "       3/10         0G     0.7794      2.863      1.065          8        640:  67%|######6   | 2/3 [00:17<00:07,  7.46s/it]\n",
      "       3/10         0G     0.7794      2.863      1.065          8        640: 100%|##########| 3/3 [00:17<00:00,  5.44s/it]\n",
      "       3/10         0G     0.7794      2.863      1.065          8        640: 100%|##########| 3/3 [00:17<00:00,  5.96s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|#####     | 1/2 [00:02<00:02,  2.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.65s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       4/10         0G     0.6318      2.738      0.946         16        640:   0%|          | 0/3 [00:07<?, ?it/s]\n",
      "       4/10         0G     0.6318      2.738      0.946         16        640:  33%|###3      | 1/3 [00:07<00:14,  7.22s/it]\n",
      "       4/10         0G     0.6619       2.52     0.9801         16        640:  33%|###3      | 1/3 [00:14<00:14,  7.22s/it]\n",
      "       4/10         0G     0.6619       2.52     0.9801         16        640:  67%|######6   | 2/3 [00:14<00:07,  7.20s/it]\n",
      "       4/10         0G     0.6761      2.523      0.961          8        640:  67%|######6   | 2/3 [00:17<00:07,  7.20s/it]\n",
      "       4/10         0G     0.6761      2.523      0.961          8        640: 100%|##########| 3/3 [00:17<00:00,  5.30s/it]\n",
      "       4/10         0G     0.6761      2.523      0.961          8        640: 100%|##########| 3/3 [00:17<00:00,  5.82s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|#####     | 1/2 [00:02<00:02,  2.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.69s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       5/10         0G      0.564      2.359     0.8923         16        640:   0%|          | 0/3 [00:07<?, ?it/s]\n",
      "       5/10         0G      0.564      2.359     0.8923         16        640:  33%|###3      | 1/3 [00:07<00:14,  7.17s/it]\n",
      "       5/10         0G     0.5317      2.254     0.8978         16        640:  33%|###3      | 1/3 [00:14<00:14,  7.17s/it]\n",
      "       5/10         0G     0.5317      2.254     0.8978         16        640:  67%|######6   | 2/3 [00:14<00:07,  7.17s/it]\n",
      "       5/10         0G     0.5049      2.239     0.8679          8        640:  67%|######6   | 2/3 [00:17<00:07,  7.17s/it]\n",
      "       5/10         0G     0.5049      2.239     0.8679          8        640: 100%|##########| 3/3 [00:17<00:00,  5.30s/it]\n",
      "       5/10         0G     0.5049      2.239     0.8679          8        640: 100%|##########| 3/3 [00:17<00:00,  5.81s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|#####     | 1/2 [00:02<00:02,  2.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.60s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       6/10         0G     0.4535      1.847     0.8908         16        640:   0%|          | 0/3 [00:07<?, ?it/s]\n",
      "       6/10         0G     0.4535      1.847     0.8908         16        640:  33%|###3      | 1/3 [00:07<00:14,  7.06s/it]\n",
      "       6/10         0G     0.4783      1.863     0.8864         16        640:  33%|###3      | 1/3 [00:14<00:14,  7.06s/it]\n",
      "       6/10         0G     0.4783      1.863     0.8864         16        640:  67%|######6   | 2/3 [00:14<00:07,  7.16s/it]\n",
      "       6/10         0G     0.4738      1.843     0.8549          8        640:  67%|######6   | 2/3 [00:17<00:07,  7.16s/it]\n",
      "       6/10         0G     0.4738      1.843     0.8549          8        640: 100%|##########| 3/3 [00:17<00:00,  5.25s/it]\n",
      "       6/10         0G     0.4738      1.843     0.8549          8        640: 100%|##########| 3/3 [00:17<00:00,  5.76s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|#####     | 1/2 [00:02<00:02,  2.59s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.59s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       7/10         0G     0.4821      1.825     0.8102         16        640:   0%|          | 0/3 [00:07<?, ?it/s]\n",
      "       7/10         0G     0.4821      1.825     0.8102         16        640:  33%|###3      | 1/3 [00:07<00:14,  7.03s/it]\n",
      "       7/10         0G     0.4595       1.76     0.8293         16        640:  33%|###3      | 1/3 [00:14<00:14,  7.03s/it]\n",
      "       7/10         0G     0.4595       1.76     0.8293         16        640:  67%|######6   | 2/3 [00:14<00:07,  7.01s/it]\n",
      "       7/10         0G     0.4361      1.697     0.8736          8        640:  67%|######6   | 2/3 [00:17<00:07,  7.01s/it]\n",
      "       7/10         0G     0.4361      1.697     0.8736          8        640: 100%|##########| 3/3 [00:17<00:00,  5.22s/it]\n",
      "       7/10         0G     0.4361      1.697     0.8736          8        640: 100%|##########| 3/3 [00:17<00:00,  5.70s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|#####     | 1/2 [00:02<00:02,  2.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.65s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       8/10         0G      0.566      1.584     0.8406         16        640:   0%|          | 0/3 [00:07<?, ?it/s]\n",
      "       8/10         0G      0.566      1.584     0.8406         16        640:  33%|###3      | 1/3 [00:07<00:14,  7.12s/it]\n",
      "       8/10         0G     0.5368      1.589     0.8558         16        640:  33%|###3      | 1/3 [00:14<00:14,  7.12s/it]\n",
      "       8/10         0G     0.5368      1.589     0.8558         16        640:  67%|######6   | 2/3 [00:14<00:07,  7.20s/it]\n",
      "       8/10         0G     0.5184      1.622     0.8479          8        640:  67%|######6   | 2/3 [00:17<00:07,  7.20s/it]\n",
      "       8/10         0G     0.5184      1.622     0.8479          8        640: 100%|##########| 3/3 [00:17<00:00,  5.29s/it]\n",
      "       8/10         0G     0.5184      1.622     0.8479          8        640: 100%|##########| 3/3 [00:17<00:00,  5.80s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|#####     | 1/2 [00:02<00:02,  2.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.65s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       9/10         0G     0.3933      1.563     0.9318         16        640:   0%|          | 0/3 [00:07<?, ?it/s]\n",
      "       9/10         0G     0.3933      1.563     0.9318         16        640:  33%|###3      | 1/3 [00:07<00:14,  7.16s/it]\n",
      "       9/10         0G     0.4095      1.466     0.9124         16        640:  33%|###3      | 1/3 [00:14<00:14,  7.16s/it]\n",
      "       9/10         0G     0.4095      1.466     0.9124         16        640:  67%|######6   | 2/3 [00:14<00:07,  7.04s/it]\n",
      "       9/10         0G     0.4732      1.473     0.9263          8        640:  67%|######6   | 2/3 [00:17<00:07,  7.04s/it]\n",
      "       9/10         0G     0.4732      1.473     0.9263          8        640: 100%|##########| 3/3 [00:17<00:00,  5.32s/it]\n",
      "       9/10         0G     0.4732      1.473     0.9263          8        640: 100%|##########| 3/3 [00:17<00:00,  5.80s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|#####     | 1/2 [00:02<00:02,  2.59s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.61s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "      10/10         0G     0.4745      1.515     0.8505         16        640:   0%|          | 0/3 [00:06<?, ?it/s]\n",
      "      10/10         0G     0.4745      1.515     0.8505         16        640:  33%|###3      | 1/3 [00:06<00:13,  6.88s/it]\n",
      "      10/10         0G     0.4444       1.45     0.8781         16        640:  33%|###3      | 1/3 [00:14<00:13,  6.88s/it]\n",
      "      10/10         0G     0.4444       1.45     0.8781         16        640:  67%|######6   | 2/3 [00:14<00:07,  7.05s/it]\n",
      "      10/10         0G     0.4497      1.452     0.8812          8        640:  67%|######6   | 2/3 [00:17<00:07,  7.05s/it]\n",
      "      10/10         0G     0.4497      1.452     0.8812          8        640: 100%|##########| 3/3 [00:17<00:00,  5.20s/it]\n",
      "      10/10         0G     0.4497      1.452     0.8812          8        640: 100%|##########| 3/3 [00:17<00:00,  5.68s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|#####     | 1/2 [00:02<00:02,  2.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:03<00:00,  1.61s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|#####     | 1/2 [00:02<00:02,  2.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:02<00:00,  1.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 2/2 [00:02<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train model=yolov8s.pt data=config.yaml epochs=10 imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0874286b-13cc-440d-9b77-65805f489ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model_path  = 'best.pt'\n",
    "model_v1 = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d5f40a-935b-4ce8-b50a-64512f530936",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_v1([\"6c452236-6176-11ef-9b98-add2bed3d97a.jpg\"])  # return a list of Results objects\n",
    "\n",
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c19da40e-1e3c-4fef-9113-f2a4faf860e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import time\n",
    "import os\n",
    "import pyautogui\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import threading\n",
    "import pyautogui\n",
    "import pydirectinput\n",
    "import mss"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa4afbc9-a992-4626-b3c2-b42a721d1657",
   "metadata": {},
   "source": [
    "Ma kilkać lewo dopóki nie będzie pod gałęzią i wtedy klika w prawo\n",
    "dopóki nie będzie pod gałęzią i wtedy kilka w lewo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98a9c182-b388-4ce9-9ff1-1185577f34b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x320 (no detections), 107.3ms\n",
      "Speed: 1.0ms preprocess, 107.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.1208103597164154 Max Loc: (114, 90)\n",
      "\n",
      "0: 640x320 1 right_log, 103.8ms\n",
      "Speed: 1.0ms preprocess, 103.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.11836853623390198 Max Loc: (8, 142)\n",
      "\n",
      "0: 640x320 2 timbermans, 98.2ms\n",
      "Speed: 2.0ms preprocess, 98.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.16554446518421173 Max Loc: (128, 473)\n",
      "\n",
      "0: 640x320 (no detections), 91.5ms\n",
      "Speed: 1.0ms preprocess, 91.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.16542686522006989 Max Loc: (128, 473)\n",
      "\n",
      "0: 640x320 (no detections), 92.7ms\n",
      "Speed: 2.0ms preprocess, 92.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.165283203125 Max Loc: (128, 473)\n",
      "\n",
      "0: 640x320 1 right_log, 90.7ms\n",
      "Speed: 1.0ms preprocess, 90.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.11256521195173264 Max Loc: (25, 234)\n",
      "\n",
      "0: 640x320 1 right_log, 109.2ms\n",
      "Speed: 1.0ms preprocess, 109.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.11256521195173264 Max Loc: (25, 234)\n",
      "\n",
      "0: 640x320 1 right_log, 94.7ms\n",
      "Speed: 1.5ms preprocess, 94.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.11256510764360428 Max Loc: (25, 234)\n",
      "\n",
      "0: 640x320 1 right_log, 106.8ms\n",
      "Speed: 1.0ms preprocess, 106.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.11256521195173264 Max Loc: (25, 234)\n",
      "\n",
      "0: 640x320 (no detections), 100.5ms\n",
      "Speed: 1.5ms preprocess, 100.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.48543187975883484 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 97.2ms\n",
      "Speed: 2.0ms preprocess, 97.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.7518890500068665 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 1 left_log, 91.7ms\n",
      "Speed: 1.5ms preprocess, 91.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.41030991077423096 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 left_log, 1 timberman, 82.7ms\n",
      "Speed: 2.0ms preprocess, 82.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4934385418891907 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 left_log, 1 timberman, 72.2ms\n",
      "Speed: 1.5ms preprocess, 72.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.49300482869148254 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 left_log, 1 timberman, 72.1ms\n",
      "Speed: 1.0ms preprocess, 72.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.7769535183906555 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 left_log, 96.2ms\n",
      "Speed: 2.0ms preprocess, 96.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4045220911502838 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 71.1ms\n",
      "Speed: 1.0ms preprocess, 71.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.5818585753440857 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 73.2ms\n",
      "Speed: 1.0ms preprocess, 73.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.43781059980392456 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 77.6ms\n",
      "Speed: 1.0ms preprocess, 77.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.49145007133483887 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 76.7ms\n",
      "Speed: 1.0ms preprocess, 76.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.49299824237823486 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 72.6ms\n",
      "Speed: 1.0ms preprocess, 72.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.48619961738586426 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 75.4ms\n",
      "Speed: 1.0ms preprocess, 75.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.49338698387145996 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 73.1ms\n",
      "Speed: 1.0ms preprocess, 73.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4929508864879608 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 72.6ms\n",
      "Speed: 1.0ms preprocess, 72.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4926856458187103 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 73.7ms\n",
      "Speed: 1.0ms preprocess, 73.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4931481182575226 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 76.1ms\n",
      "Speed: 1.0ms preprocess, 76.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4932876527309418 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 72.6ms\n",
      "Speed: 1.5ms preprocess, 72.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.7772394418716431 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 (no detections), 75.1ms\n",
      "Speed: 1.0ms preprocess, 75.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.42513835430145264 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 1 left_log, 70.1ms\n",
      "Speed: 1.0ms preprocess, 70.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.6922335028648376 Max Loc: (86, 508)\n",
      "\n",
      "0: 640x320 (no detections), 74.6ms\n",
      "Speed: 1.0ms preprocess, 74.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.43910932540893555 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 (no detections), 80.2ms\n",
      "Speed: 1.0ms preprocess, 80.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.6533666849136353 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 (no detections), 88.7ms\n",
      "Speed: 2.5ms preprocess, 88.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.40447479486465454 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 1 left_log, 74.1ms\n",
      "Speed: 1.0ms preprocess, 74.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4856696128845215 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 1 left_log, 77.1ms\n",
      "Speed: 2.0ms preprocess, 77.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.5889080762863159 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 71.6ms\n",
      "Speed: 2.0ms preprocess, 71.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.42873698472976685 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 (no detections), 79.6ms\n",
      "Speed: 0.0ms preprocess, 79.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.6533669233322144 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 2 left_logs, 90.7ms\n",
      "Speed: 1.0ms preprocess, 90.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4012012779712677 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 1 left_log, 74.6ms\n",
      "Speed: 1.0ms preprocess, 74.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.48543021082878113 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 1 left_log, 73.6ms\n",
      "Speed: 1.0ms preprocess, 73.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4854315221309662 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 1 left_log, 80.9ms\n",
      "Speed: 1.5ms preprocess, 80.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4854315221309662 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 75.1ms\n",
      "Speed: 1.0ms preprocess, 75.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4854315221309662 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 76.6ms\n",
      "Speed: 1.0ms preprocess, 76.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.48543187975883484 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 75.1ms\n",
      "Speed: 1.0ms preprocess, 75.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.47621774673461914 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 74.6ms\n",
      "Speed: 1.0ms preprocess, 74.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.48333969712257385 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 75.1ms\n",
      "Speed: 1.5ms preprocess, 75.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.45891904830932617 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 72.6ms\n",
      "Speed: 1.0ms preprocess, 72.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.48566997051239014 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 72.6ms\n",
      "Speed: 1.0ms preprocess, 72.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.48357629776000977 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 1 timberman, 78.1ms\n",
      "Speed: 1.0ms preprocess, 78.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4735519289970398 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 74.7ms\n",
      "Speed: 1.0ms preprocess, 74.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.5744085907936096 Max Loc: (86, 497)\n",
      "\n",
      "0: 640x320 (no detections), 105.2ms\n",
      "Speed: 1.0ms preprocess, 105.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.43910911679267883 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 75.6ms\n",
      "Speed: 1.0ms preprocess, 75.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.49075570702552795 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 75.7ms\n",
      "Speed: 1.0ms preprocess, 75.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4932798445224762 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 2 timbermans, 82.1ms\n",
      "Speed: 2.0ms preprocess, 82.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4903082251548767 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 79.7ms\n",
      "Speed: 2.0ms preprocess, 79.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4918319284915924 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 (no detections), 75.6ms\n",
      "Speed: 0.5ms preprocess, 75.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.6302409768104553 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 (no detections), 74.7ms\n",
      "Speed: 1.0ms preprocess, 74.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4046453833580017 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 78.1ms\n",
      "Speed: 1.0ms preprocess, 78.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4835759401321411 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 77.1ms\n",
      "Speed: 2.0ms preprocess, 77.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4835759401321411 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 75.6ms\n",
      "Speed: 1.0ms preprocess, 75.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.5886732339859009 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 77.6ms\n",
      "Speed: 1.5ms preprocess, 77.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4387117326259613 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 74.6ms\n",
      "Speed: 1.0ms preprocess, 74.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.483862966299057 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 74.6ms\n",
      "Speed: 1.0ms preprocess, 74.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.49280813336372375 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 73.1ms\n",
      "Speed: 1.0ms preprocess, 73.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4931481182575226 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 (no detections), 89.1ms\n",
      "Speed: 1.0ms preprocess, 89.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.6533665060997009 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 (no detections), 77.6ms\n",
      "Speed: 1.0ms preprocess, 77.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4044739007949829 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 75.6ms\n",
      "Speed: 1.0ms preprocess, 75.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4856683015823364 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 77.7ms\n",
      "Speed: 1.0ms preprocess, 77.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.48333901166915894 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 75.2ms\n",
      "Speed: 1.0ms preprocess, 75.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4854322373867035 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 75.7ms\n",
      "Speed: 1.0ms preprocess, 75.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4854315221309662 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 75.1ms\n",
      "Speed: 1.0ms preprocess, 75.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.48566925525665283 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 74.6ms\n",
      "Speed: 1.0ms preprocess, 74.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.7496804594993591 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 76.7ms\n",
      "Speed: 1.0ms preprocess, 76.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.42776384949684143 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 77.6ms\n",
      "Speed: 1.0ms preprocess, 77.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4926612377166748 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 83.3ms\n",
      "Speed: 1.0ms preprocess, 83.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.493025541305542 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 77.6ms\n",
      "Speed: 1.0ms preprocess, 77.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.49299341440200806 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 112.6ms\n",
      "Speed: 1.5ms preprocess, 112.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.49192947149276733 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 79.7ms\n",
      "Speed: 1.0ms preprocess, 79.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4929859936237335 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 80.2ms\n",
      "Speed: 1.0ms preprocess, 80.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4934385418891907 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 77.1ms\n",
      "Speed: 1.0ms preprocess, 77.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4928077459335327 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 (no detections), 76.1ms\n",
      "Speed: 1.0ms preprocess, 76.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.6515787243843079 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 (no detections), 76.1ms\n",
      "Speed: 1.0ms preprocess, 76.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.39643165469169617 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 83.1ms\n",
      "Speed: 1.0ms preprocess, 83.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.48333969712257385 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 73.6ms\n",
      "Speed: 1.0ms preprocess, 73.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4854315221309662 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 77.2ms\n",
      "Speed: 1.5ms preprocess, 77.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4854315221309662 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 82.2ms\n",
      "Speed: 1.0ms preprocess, 82.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.7518894076347351 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 77.1ms\n",
      "Speed: 1.5ms preprocess, 77.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4281659722328186 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 72.6ms\n",
      "Speed: 2.0ms preprocess, 72.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.7772394418716431 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 (no detections), 76.1ms\n",
      "Speed: 1.0ms preprocess, 76.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4235328733921051 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 95.0ms\n",
      "Speed: 1.0ms preprocess, 95.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.7515830397605896 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 76.1ms\n",
      "Speed: 2.5ms preprocess, 76.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.43086352944374084 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 (no detections), 74.1ms\n",
      "Speed: 1.0ms preprocess, 74.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.6533671021461487 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 (no detections), 77.1ms\n",
      "Speed: 1.0ms preprocess, 77.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.42696964740753174 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 76.2ms\n",
      "Speed: 1.5ms preprocess, 76.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.5856586694717407 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 75.2ms\n",
      "Speed: 1.0ms preprocess, 75.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.42964842915534973 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 74.1ms\n",
      "Speed: 2.0ms preprocess, 74.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.49327167868614197 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 75.1ms\n",
      "Speed: 1.0ms preprocess, 75.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4926619827747345 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 75.6ms\n",
      "Speed: 1.0ms preprocess, 75.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.49328023195266724 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 85.7ms\n",
      "Speed: 2.0ms preprocess, 85.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4928077459335327 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 77.6ms\n",
      "Speed: 2.0ms preprocess, 77.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4935033619403839 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 (no detections), 74.6ms\n",
      "Speed: 1.0ms preprocess, 74.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.6302406191825867 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 (no detections), 77.6ms\n",
      "Speed: 1.0ms preprocess, 77.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.426970511674881 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 77.1ms\n",
      "Speed: 1.5ms preprocess, 77.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.5925397276878357 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 94.7ms\n",
      "Speed: 1.0ms preprocess, 94.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4390272796154022 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 1 timberman, 78.6ms\n",
      "Speed: 1.5ms preprocess, 78.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.6143710017204285 Max Loc: (115, 507)\n",
      "\n",
      "0: 640x320 (no detections), 95.0ms\n",
      "Speed: 2.0ms preprocess, 95.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.42353323101997375 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 75.2ms\n",
      "Speed: 1.0ms preprocess, 75.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.4854322373867035 Max Loc: (86, 510)\n",
      "\n",
      "0: 640x320 (no detections), 96.5ms\n",
      "Speed: 1.0ms preprocess, 96.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "Max Val: 0.741294264793396 Max Loc: (86, 510)\n"
     ]
    }
   ],
   "source": [
    "import mss\n",
    "\n",
    "# Part of the screen to capture\n",
    "dimensionsLeft = {\n",
    "        'top': 50,\n",
    "        'left': 650,\n",
    "        'width': 400,\n",
    "        'height': 800\n",
    "}\n",
    "dimensionsRight = {\n",
    "        'top': 50,\n",
    "        'left': 1000,\n",
    "        'width': 400,\n",
    "        'height': 800\n",
    "}\n",
    "    \n",
    "# Images to compare with part of the screen\n",
    "caneLeft = cv2.imread('l_c.png')\n",
    "caneRight = cv2.imread('r_c.png')\n",
    "\n",
    "monitor = {\"top\": 40, \"left\": 0, \"width\": 1920, \"height\": 1080}\n",
    "# FLag True\n",
    "left = True\n",
    "\n",
    "\n",
    "w = caneLeft.shape[1]\n",
    "h = caneLeft.shape[0]\n",
    "last_time = time.time()\n",
    "with mss.mss() as sct:\n",
    "    \n",
    "\n",
    "\n",
    "    while True:\n",
    "  \n",
    "        if left:\n",
    "            img = np.asarray(sct.grab(dimensionsLeft))\n",
    "            can = caneLeft\n",
    "        else:\n",
    "            img = np.array(sct.grab(dimensionsRight))\n",
    "            can = caneRight\n",
    "        \n",
    "          \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        can = cv2.cvtColor(can , cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "\n",
    "        results = model_v1(img)\n",
    "        img = results[0].plot()\n",
    "        # Zakładamy, że wyniki są w postaci listy obiektów wykrytych\n",
    "\n",
    "\n",
    "        \n",
    "        '''\n",
    "        for box in results[0].boxes:\n",
    "            # Pobierz współrzędne ramki (box)\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # map(int, ...) konwertuje współrzędne na liczby całkowite\n",
    "            cv2.rectangle(img, (x1, y1, x2, y2), (0, 255, 0), 4)\n",
    "        '''            \n",
    "\n",
    "        \n",
    "        \n",
    "        res = cv2.matchTemplate(img , can ,  cv2.TM_CCOEFF_NORMED)\n",
    "        _, maxVal, _, maxLoc = cv2.minMaxLoc(res)\n",
    "        print(f\"Max Val: {maxVal} Max Loc: {maxLoc}\")\n",
    "    \n",
    "        threshold = 0.5\n",
    "\n",
    "\n",
    "        if maxVal >= threshold:\n",
    "            left = not left\n",
    "            \n",
    "        \n",
    "        if left:\n",
    "            pyautogui.press('left')\n",
    "        else:\n",
    "            pyautogui.press('right')\n",
    "        \n",
    "        \n",
    "        img = cv2.cvtColor(img , cv2.COLOR_BGR2RGB)\n",
    "        cv2.imshow(\"OpenCV/Numpy normal\", img)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        # print(f\"fps: {1 / (time.time() - last_time)}\")\n",
    "    \n",
    "            \n",
    "        if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4e47fb-3c7d-4b2c-9125-7c6b2970cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def take_screenshot(model):\n",
    "\n",
    "    pyautogui.FAILSAFE = False\n",
    "    # Take screenshot\n",
    "    screenshot = pyautogui.screenshot()\n",
    "    screenshot = Image.frombytes('RGB', screenshot.size, screenshot.tobytes())\n",
    "    \n",
    "    screenshot_np = np.array(screenshot)\n",
    "    screenshot_np = cv2.cvtColor(screenshot_np, cv2.COLOR_RGB2BGR)\n",
    "    threshold = 0.5\n",
    "    \n",
    "\n",
    "    while True: \n",
    "        results = model(screenshot_np)[0]\n",
    "        for result in results.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, class_id = result\n",
    "            \n",
    "           \n",
    "            cv2.rectangle(screenshot_np, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n",
    "            cv2.putText(screenshot_np, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "                \n",
    "        cv2.imshow('Detection', screenshot_np)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Clean up: destroy all windows\n",
    "    cv2.destroyAllWindows()\n",
    "take_screenshot(model)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47220b5d-6246-4772-8456-20ff08a26ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyautogui.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a540dea7-7ff8-4e42-ac58-3949b8c7487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "while True:\n",
    "    # Przechwyć zrzut ekranu\n",
    "    screenshot = pyautogui.screenshot()\n",
    "\n",
    "    # Konwertuj zrzut ekranu do tablicy numpy\n",
    "    img = np.array(screenshot)\n",
    "    \n",
    "    # Konwertuj kolory z RGB na BGR (OpenCV używa BGR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Wykonaj predykcję na obrazie\n",
    "    results = model(img)\n",
    "    boxes = results[0].boxes.xyxy.tolist()\n",
    "    print(boxes)\n",
    "    if len(boxes) > 0 :\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box\n",
    "            print(x1 ,y1,x2 ,y2)\n",
    "            if x1 > 0:\n",
    "                annotated_img = cv2.rectangle(screenshot_np, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n",
    "       \n",
    "\n",
    "    # Wyświetl obraz z predykcjami\n",
    "    cv2.imshow('YOLOv8 Predictions', annotated_img)\n",
    "\n",
    "    # Zakończ, gdy użytkownik naciśnie 'q'\n",
    "    if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94add81-36be-40a9-aa2e-b47791f6ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with mss.mss() as sct:\n",
    "    while True:\n",
    "        monitor = {\"top\": 40, \"left\": 0, \"width\": 1920, \"height\": 1080}\n",
    "\n",
    "        screenshot = sct.grab(monitor)\n",
    "        frame = np.array(screenshot)\n",
    "    \n",
    "        # Convert to correct color format\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)\n",
    "    \n",
    "        # Process frame\n",
    "        #results = model(frame)\n",
    "        results = model_v1(frame)[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        for result in results.boxes.data.tolist(:\n",
    "            print(result)\n",
    "            x1, y1, x2, y2, score, class_id = result\n",
    "    \n",
    "            if score > threshold:\n",
    "                frame =  cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n",
    "                frame = cv2.putText(frame, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "        # To display the predictions\n",
    "        cv2.imshow('Monitor 1', frame)\n",
    "        cv2.waitKey(1)\n",
    "        if cv2.waitKey(3) & 0xFF == ord(\"q\"):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b87fb94-d339-4a79-8d11-7919cc8c9b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731704af-602e-4e4e-9da5-f3672ef3a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import mss\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Assuming you have loaded your model before this loop\n",
    "# model = load_your_model()\n",
    "\n",
    "threshold = 0.1  # Adjust your threshold as needed\n",
    "\n",
    "with mss.mss() as sct:\n",
    "    while True:\n",
    "        monitor = {\"top\": 40, \"left\": 0, \"width\": 1920, \"height\": 1080}\n",
    "\n",
    "        screenshot = sct.grab(monitor)\n",
    "        frame = np.array(screenshot)\n",
    "    \n",
    "        # Convert to correct color format\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)\n",
    "    \n",
    "        # Process frame using the model\n",
    "        results = model_v1(frame)[0]\n",
    "        \n",
    "        print(\"Boxes Data:\", results.boxes.data)\n",
    "        print(\"Class Names:\", results.names)\n",
    "        # Loop through detected objects and draw boxes\n",
    "        for result in results.boxes.data.tolist():\n",
    "            print(result)\n",
    "            x1, y1, x2, y2, score, class_id = result\n",
    "    \n",
    "            if score > threshold:\n",
    "                frame = cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n",
    "                frame = cv2.putText(frame, results.names[int(class_id)].upper(), \n",
    "                                    (int(x1), int(y1 - 10)),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "        \n",
    "        # Display the predictions\n",
    "        cv2.imshow('Monitor 1', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63245ab7-c93c-4732-9cae-5116493fc8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
